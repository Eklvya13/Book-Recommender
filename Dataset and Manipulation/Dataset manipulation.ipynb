{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2d4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas and numpy \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43887aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing books.csv as a DataFrame\n",
    "books = pd.read_csv(\"books.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb8139e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "books.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2689a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking only useful columns\n",
    "books = books[['wikipedia_id', 'title', 'author', 'genre', 'summary']]\n",
    "books.info()\n",
    "# Saving Author name for future use\n",
    "temp = books['author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51da04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops all rows whick have a NULL value at anu column\n",
    "books.isnull().sum()\n",
    "books.dropna(inplace=True)\n",
    "books.isnull().sum()\n",
    "books.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac018f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/ast.html\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b5346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for cleaning the list or dict (takes special symbols literally as strings)\n",
    "def clean(obj):\n",
    "    obj = ast.literal_eval(obj)\n",
    "    li = []\n",
    "    for i in obj:\n",
    "        li.append(obj[i])\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3283e",
   "metadata": {},
   "outputs": [],
   "source": [
    "books['genre'] = books['genre'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ed84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string to list\n",
    "books['summary'] = books['summary'].apply(lambda x: x.split())\n",
    "# Remove Spaces\n",
    "books['summary'] = books['summary'].apply(lambda x:[i.replace(\" \",\"\") for i in x])\n",
    "books['author'] = books['author'].apply(lambda x: x.replace(\" \", \"\"))\n",
    "books['genre'] = books['genre'].apply(lambda x: [i.replace(\" \", \"\") for i in x])\n",
    "books['author'] = books['author'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6c2d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining author, genre, and summary as tags \n",
    "books['tags'] = books['genre'] + books['author'] + books['summary']\n",
    "books['tags'] = books['tags'].apply(lambda x:[i.lower() for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8dd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataframe\n",
    "dframe = books[['wikipedia_id', 'title', 'tags']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5888d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting list of strings to a singular large string with spaces\n",
    "dframe['tags'] = dframe['tags'].apply(lambda x:\" \".join(x))\n",
    "dframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c2c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing scikit learn : https://scikit-learn.org/stable/index.html   (Simple and efficient tools for predictive data analysis)\n",
    "# Importing nltk : https://www.nltk.org/    (NLTK is a leading platform for building Python programs to work with human language data)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features= 5000, stop_words='english')\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f2faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to 'stem' strings. More on it : https://www.nltk.org/api/nltk.stem.porter.html#module-nltk.stem.porter\n",
    "def stem(text):\n",
    "    temp = []\n",
    "    \n",
    "    for i in text.split():\n",
    "        temp.append(ps.stem(i))\n",
    "    \n",
    "    return \" \".join(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cf7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dframe['tags'] = dframe['tags'].apply(stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678f0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appling Count Vectorisation to plot data , more on it :https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "cv = CountVectorizer(max_features= 5000, stop_words='english')\n",
    "vectors = cv.fit_transform(dframe['tags']).toarray()\n",
    "vectors.shape\n",
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393bbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function which gives cosines of all points with respect to all other points. More on it : https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6d4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list for cosines\n",
    "similarity = cosine_similarity(vectors) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75885fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a temporary function to verify results\n",
    "def recommend(title):\n",
    "    book_index = dframe[dframe['title'] == title].index[0]\n",
    "    plots = similarity[book_index]\n",
    "    recommended = sorted(enumerate(plots), reverse=True, key= lambda x:x[1])[1:6]\n",
    "    for recommendation in recommended:\n",
    "        print(dframe.iloc[recommendation[0]].title)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pickle module implements binary protocols for serializing and de-serializing a Python object structure.\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e976dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dataframe\n",
    "book_info = dframe[['wikipedia_id', 'title']]\n",
    "book_info['author'] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5343ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which returns a list of indexes top 5 recommendations of all elements\n",
    "def extract(similarity):\n",
    "    main = []\n",
    "    for element in similarity:\n",
    "        temp = []\n",
    "        recommended = []\n",
    "        temp = sorted(enumerate(element), reverse=True, key= lambda x:x[1])[1:6]\n",
    "        for i in temp:\n",
    "            recommended.append(i[0])\n",
    "        main.append(recommended)\n",
    "    return main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb05d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = extract(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2405f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.python.org/3/library/pickle.html\n",
    "pickle.dump(book_info.to_dict(), open('finbook_dict.pkl', 'wb'))\n",
    "pickle.dump(main, open('fin_recommend.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
